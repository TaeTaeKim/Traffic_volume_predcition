{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torch.utils import data\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 생성기가 항상 일정한 값을 출력하게 하기 위해 seed 고정\n",
    "random_seed = 2021\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join('/USER/Taeyun/Traffic_TimeSeires')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df =pd.read_csv(os.path.join(DATASET_PATH, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.279000e+03</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "      <td>3279.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.020030e+07</td>\n",
       "      <td>11.471485</td>\n",
       "      <td>231676.505337</td>\n",
       "      <td>66678.847514</td>\n",
       "      <td>7143.639829</td>\n",
       "      <td>17331.323879</td>\n",
       "      <td>6628.811833</td>\n",
       "      <td>4680.581580</td>\n",
       "      <td>99293.113144</td>\n",
       "      <td>4392.170784</td>\n",
       "      <td>...</td>\n",
       "      <td>5146.086612</td>\n",
       "      <td>10912.152181</td>\n",
       "      <td>27170.792925</td>\n",
       "      <td>13920.547728</td>\n",
       "      <td>4869.270204</td>\n",
       "      <td>14628.283623</td>\n",
       "      <td>2461.659652</td>\n",
       "      <td>12099.310765</td>\n",
       "      <td>7945.500762</td>\n",
       "      <td>13955.133882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.329223e+02</td>\n",
       "      <td>6.925364</td>\n",
       "      <td>121980.705751</td>\n",
       "      <td>41643.311713</td>\n",
       "      <td>5571.818718</td>\n",
       "      <td>13324.699817</td>\n",
       "      <td>4783.716536</td>\n",
       "      <td>3532.599568</td>\n",
       "      <td>58442.772440</td>\n",
       "      <td>2855.469702</td>\n",
       "      <td>...</td>\n",
       "      <td>3874.383388</td>\n",
       "      <td>6166.799088</td>\n",
       "      <td>15608.559732</td>\n",
       "      <td>7125.224311</td>\n",
       "      <td>4082.563691</td>\n",
       "      <td>9570.485274</td>\n",
       "      <td>1876.079260</td>\n",
       "      <td>7996.564920</td>\n",
       "      <td>5208.472823</td>\n",
       "      <td>9277.435792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.020010e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.020020e+07</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>111763.500000</td>\n",
       "      <td>23461.500000</td>\n",
       "      <td>1898.500000</td>\n",
       "      <td>5187.500000</td>\n",
       "      <td>1697.500000</td>\n",
       "      <td>1311.000000</td>\n",
       "      <td>42964.000000</td>\n",
       "      <td>1524.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1304.500000</td>\n",
       "      <td>4479.000000</td>\n",
       "      <td>11522.500000</td>\n",
       "      <td>7208.500000</td>\n",
       "      <td>1492.000000</td>\n",
       "      <td>4975.500000</td>\n",
       "      <td>713.500000</td>\n",
       "      <td>3607.500000</td>\n",
       "      <td>2534.000000</td>\n",
       "      <td>3952.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.020031e+07</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>266717.000000</td>\n",
       "      <td>73756.000000</td>\n",
       "      <td>6924.000000</td>\n",
       "      <td>16623.000000</td>\n",
       "      <td>7004.000000</td>\n",
       "      <td>4675.000000</td>\n",
       "      <td>111362.000000</td>\n",
       "      <td>4741.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5134.000000</td>\n",
       "      <td>12865.000000</td>\n",
       "      <td>31100.000000</td>\n",
       "      <td>15916.000000</td>\n",
       "      <td>4228.000000</td>\n",
       "      <td>15863.000000</td>\n",
       "      <td>2199.000000</td>\n",
       "      <td>13438.000000</td>\n",
       "      <td>8545.000000</td>\n",
       "      <td>15139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020041e+07</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>327157.000000</td>\n",
       "      <td>99830.500000</td>\n",
       "      <td>10882.500000</td>\n",
       "      <td>25910.500000</td>\n",
       "      <td>10314.000000</td>\n",
       "      <td>6924.500000</td>\n",
       "      <td>140880.000000</td>\n",
       "      <td>6661.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8128.000000</td>\n",
       "      <td>16198.000000</td>\n",
       "      <td>39064.500000</td>\n",
       "      <td>19433.000000</td>\n",
       "      <td>6756.000000</td>\n",
       "      <td>21724.000000</td>\n",
       "      <td>3749.500000</td>\n",
       "      <td>18715.500000</td>\n",
       "      <td>12490.500000</td>\n",
       "      <td>22057.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>580098.000000</td>\n",
       "      <td>200808.000000</td>\n",
       "      <td>45869.000000</td>\n",
       "      <td>114833.000000</td>\n",
       "      <td>24596.000000</td>\n",
       "      <td>24639.000000</td>\n",
       "      <td>292004.000000</td>\n",
       "      <td>14163.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21409.000000</td>\n",
       "      <td>25891.000000</td>\n",
       "      <td>76629.000000</td>\n",
       "      <td>35192.000000</td>\n",
       "      <td>28531.000000</td>\n",
       "      <td>45531.000000</td>\n",
       "      <td>10581.000000</td>\n",
       "      <td>38061.000000</td>\n",
       "      <td>21229.000000</td>\n",
       "      <td>36915.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 날짜           시간             10            100           101  \\\n",
       "count  3.279000e+03  3279.000000    3279.000000    3279.000000   3279.000000   \n",
       "mean   2.020030e+07    11.471485  231676.505337   66678.847514   7143.639829   \n",
       "std    1.329223e+02     6.925364  121980.705751   41643.311713   5571.818718   \n",
       "min    2.020010e+07     0.000000       0.000000       0.000000      0.000000   \n",
       "25%    2.020020e+07     5.000000  111763.500000   23461.500000   1898.500000   \n",
       "50%    2.020031e+07    11.000000  266717.000000   73756.000000   6924.000000   \n",
       "75%    2.020041e+07    17.000000  327157.000000   99830.500000  10882.500000   \n",
       "max    2.020052e+07    23.000000  580098.000000  200808.000000  45869.000000   \n",
       "\n",
       "                 120           121           140            150           160  \\\n",
       "count    3279.000000   3279.000000   3279.000000    3279.000000   3279.000000   \n",
       "mean    17331.323879   6628.811833   4680.581580   99293.113144   4392.170784   \n",
       "std     13324.699817   4783.716536   3532.599568   58442.772440   2855.469702   \n",
       "min         0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "25%      5187.500000   1697.500000   1311.000000   42964.000000   1524.500000   \n",
       "50%     16623.000000   7004.000000   4675.000000  111362.000000   4741.000000   \n",
       "75%     25910.500000  10314.000000   6924.500000  140880.000000   6661.000000   \n",
       "max    114833.000000  24596.000000  24639.000000  292004.000000  14163.000000   \n",
       "\n",
       "       ...          1020          1040          1100          1200  \\\n",
       "count  ...   3279.000000   3279.000000   3279.000000   3279.000000   \n",
       "mean   ...   5146.086612  10912.152181  27170.792925  13920.547728   \n",
       "std    ...   3874.383388   6166.799088  15608.559732   7125.224311   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...   1304.500000   4479.000000  11522.500000   7208.500000   \n",
       "50%    ...   5134.000000  12865.000000  31100.000000  15916.000000   \n",
       "75%    ...   8128.000000  16198.000000  39064.500000  19433.000000   \n",
       "max    ...  21409.000000  25891.000000  76629.000000  35192.000000   \n",
       "\n",
       "               1510          2510          3000          4510          5510  \\\n",
       "count   3279.000000   3279.000000   3279.000000   3279.000000   3279.000000   \n",
       "mean    4869.270204  14628.283623   2461.659652  12099.310765   7945.500762   \n",
       "std     4082.563691   9570.485274   1876.079260   7996.564920   5208.472823   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     1492.000000   4975.500000    713.500000   3607.500000   2534.000000   \n",
       "50%     4228.000000  15863.000000   2199.000000  13438.000000   8545.000000   \n",
       "75%     6756.000000  21724.000000   3749.500000  18715.500000  12490.500000   \n",
       "max    28531.000000  45531.000000  10581.000000  38061.000000  21229.000000   \n",
       "\n",
       "               6000  \n",
       "count   3279.000000  \n",
       "mean   13955.133882  \n",
       "std     9277.435792  \n",
       "min        0.000000  \n",
       "25%     3952.000000  \n",
       "50%    15139.000000  \n",
       "75%    22057.500000  \n",
       "max    36915.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df=pd.read_csv(os.path.join(DATASET_PATH, 'validate.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.360000e+02</td>\n",
       "      <td>336.00000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>235343.178571</td>\n",
       "      <td>71733.666667</td>\n",
       "      <td>7487.821429</td>\n",
       "      <td>19463.369048</td>\n",
       "      <td>6996.550595</td>\n",
       "      <td>5077.711310</td>\n",
       "      <td>102803.354167</td>\n",
       "      <td>4611.598214</td>\n",
       "      <td>...</td>\n",
       "      <td>5495.931548</td>\n",
       "      <td>12047.080357</td>\n",
       "      <td>25495.544643</td>\n",
       "      <td>14492.982143</td>\n",
       "      <td>5274.627976</td>\n",
       "      <td>16028.535714</td>\n",
       "      <td>2401.651786</td>\n",
       "      <td>13426.627976</td>\n",
       "      <td>8977.973214</td>\n",
       "      <td>14981.702381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.037141e+00</td>\n",
       "      <td>6.93251</td>\n",
       "      <td>117811.294711</td>\n",
       "      <td>43156.834589</td>\n",
       "      <td>5324.147176</td>\n",
       "      <td>13039.262009</td>\n",
       "      <td>4900.174019</td>\n",
       "      <td>3595.835251</td>\n",
       "      <td>56432.536386</td>\n",
       "      <td>2866.635243</td>\n",
       "      <td>...</td>\n",
       "      <td>3952.463967</td>\n",
       "      <td>6583.668086</td>\n",
       "      <td>13846.890911</td>\n",
       "      <td>7081.452424</td>\n",
       "      <td>3706.415352</td>\n",
       "      <td>9929.888516</td>\n",
       "      <td>1671.879588</td>\n",
       "      <td>8268.859967</td>\n",
       "      <td>5603.276265</td>\n",
       "      <td>9589.916393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.020051e+07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.020051e+07</td>\n",
       "      <td>5.75000</td>\n",
       "      <td>124277.500000</td>\n",
       "      <td>26059.500000</td>\n",
       "      <td>2058.000000</td>\n",
       "      <td>6277.750000</td>\n",
       "      <td>1806.750000</td>\n",
       "      <td>1426.500000</td>\n",
       "      <td>49778.250000</td>\n",
       "      <td>1854.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>1485.750000</td>\n",
       "      <td>5046.500000</td>\n",
       "      <td>11302.000000</td>\n",
       "      <td>8489.500000</td>\n",
       "      <td>1860.750000</td>\n",
       "      <td>5879.250000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>4374.000000</td>\n",
       "      <td>3198.000000</td>\n",
       "      <td>4672.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>291569.500000</td>\n",
       "      <td>84219.500000</td>\n",
       "      <td>7585.500000</td>\n",
       "      <td>20308.000000</td>\n",
       "      <td>7565.000000</td>\n",
       "      <td>5329.000000</td>\n",
       "      <td>119572.000000</td>\n",
       "      <td>5062.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5640.000000</td>\n",
       "      <td>14996.500000</td>\n",
       "      <td>29671.000000</td>\n",
       "      <td>17037.500000</td>\n",
       "      <td>4891.000000</td>\n",
       "      <td>17802.500000</td>\n",
       "      <td>2363.500000</td>\n",
       "      <td>15901.500000</td>\n",
       "      <td>9662.500000</td>\n",
       "      <td>16447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>17.25000</td>\n",
       "      <td>326878.250000</td>\n",
       "      <td>104994.750000</td>\n",
       "      <td>11626.250000</td>\n",
       "      <td>28508.250000</td>\n",
       "      <td>10776.750000</td>\n",
       "      <td>7523.750000</td>\n",
       "      <td>144746.250000</td>\n",
       "      <td>6806.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>8689.750000</td>\n",
       "      <td>17698.500000</td>\n",
       "      <td>37066.500000</td>\n",
       "      <td>19961.750000</td>\n",
       "      <td>7417.000000</td>\n",
       "      <td>23388.750000</td>\n",
       "      <td>3497.500000</td>\n",
       "      <td>20104.250000</td>\n",
       "      <td>13849.250000</td>\n",
       "      <td>23266.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>439173.000000</td>\n",
       "      <td>150733.000000</td>\n",
       "      <td>19038.000000</td>\n",
       "      <td>53098.000000</td>\n",
       "      <td>17634.000000</td>\n",
       "      <td>14861.000000</td>\n",
       "      <td>226740.000000</td>\n",
       "      <td>10638.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15828.000000</td>\n",
       "      <td>21257.000000</td>\n",
       "      <td>48132.000000</td>\n",
       "      <td>26537.000000</td>\n",
       "      <td>15578.000000</td>\n",
       "      <td>36225.000000</td>\n",
       "      <td>6220.000000</td>\n",
       "      <td>29441.000000</td>\n",
       "      <td>19906.000000</td>\n",
       "      <td>31504.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 날짜         시간             10            100           101  \\\n",
       "count  3.360000e+02  336.00000     336.000000     336.000000    336.000000   \n",
       "mean   2.020052e+07   11.50000  235343.178571   71733.666667   7487.821429   \n",
       "std    4.037141e+00    6.93251  117811.294711   43156.834589   5324.147176   \n",
       "min    2.020051e+07    0.00000       0.000000       0.000000      0.000000   \n",
       "25%    2.020051e+07    5.75000  124277.500000   26059.500000   2058.000000   \n",
       "50%    2.020052e+07   11.50000  291569.500000   84219.500000   7585.500000   \n",
       "75%    2.020052e+07   17.25000  326878.250000  104994.750000  11626.250000   \n",
       "max    2.020052e+07   23.00000  439173.000000  150733.000000  19038.000000   \n",
       "\n",
       "                120           121           140            150           160  \\\n",
       "count    336.000000    336.000000    336.000000     336.000000    336.000000   \n",
       "mean   19463.369048   6996.550595   5077.711310  102803.354167   4611.598214   \n",
       "std    13039.262009   4900.174019   3595.835251   56432.536386   2866.635243   \n",
       "min        0.000000      0.000000      0.000000       0.000000      0.000000   \n",
       "25%     6277.750000   1806.750000   1426.500000   49778.250000   1854.250000   \n",
       "50%    20308.000000   7565.000000   5329.000000  119572.000000   5062.000000   \n",
       "75%    28508.250000  10776.750000   7523.750000  144746.250000   6806.250000   \n",
       "max    53098.000000  17634.000000  14861.000000  226740.000000  10638.000000   \n",
       "\n",
       "       ...          1020          1040          1100          1200  \\\n",
       "count  ...    336.000000    336.000000    336.000000    336.000000   \n",
       "mean   ...   5495.931548  12047.080357  25495.544643  14492.982143   \n",
       "std    ...   3952.463967   6583.668086  13846.890911   7081.452424   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...   1485.750000   5046.500000  11302.000000   8489.500000   \n",
       "50%    ...   5640.000000  14996.500000  29671.000000  17037.500000   \n",
       "75%    ...   8689.750000  17698.500000  37066.500000  19961.750000   \n",
       "max    ...  15828.000000  21257.000000  48132.000000  26537.000000   \n",
       "\n",
       "               1510          2510         3000          4510          5510  \\\n",
       "count    336.000000    336.000000   336.000000    336.000000    336.000000   \n",
       "mean    5274.627976  16028.535714  2401.651786  13426.627976   8977.973214   \n",
       "std     3706.415352   9929.888516  1671.879588   8268.859967   5603.276265   \n",
       "min        0.000000      0.000000     0.000000      0.000000      0.000000   \n",
       "25%     1860.750000   5879.250000   795.000000   4374.000000   3198.000000   \n",
       "50%     4891.000000  17802.500000  2363.500000  15901.500000   9662.500000   \n",
       "75%     7417.000000  23388.750000  3497.500000  20104.250000  13849.250000   \n",
       "max    15578.000000  36225.000000  6220.000000  29441.000000  19906.000000   \n",
       "\n",
       "               6000  \n",
       "count    336.000000  \n",
       "mean   14981.702381  \n",
       "std     9589.916393  \n",
       "min        0.000000  \n",
       "25%     4672.500000  \n",
       "50%    16447.000000  \n",
       "75%    23266.250000  \n",
       "max    31504.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(DATASET_PATH, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>시간</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>140</th>\n",
       "      <th>150</th>\n",
       "      <th>160</th>\n",
       "      <th>...</th>\n",
       "      <th>1020</th>\n",
       "      <th>1040</th>\n",
       "      <th>1100</th>\n",
       "      <th>1200</th>\n",
       "      <th>1510</th>\n",
       "      <th>2510</th>\n",
       "      <th>3000</th>\n",
       "      <th>4510</th>\n",
       "      <th>5510</th>\n",
       "      <th>6000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.360000e+02</td>\n",
       "      <td>336.00000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>118874.625000</td>\n",
       "      <td>36042.446429</td>\n",
       "      <td>3243.547619</td>\n",
       "      <td>9309.401786</td>\n",
       "      <td>2996.229167</td>\n",
       "      <td>2012.163690</td>\n",
       "      <td>51864.145833</td>\n",
       "      <td>1835.991071</td>\n",
       "      <td>...</td>\n",
       "      <td>2302.880952</td>\n",
       "      <td>5596.458333</td>\n",
       "      <td>11984.901786</td>\n",
       "      <td>6884.318452</td>\n",
       "      <td>2203.113095</td>\n",
       "      <td>7539.523810</td>\n",
       "      <td>602.684524</td>\n",
       "      <td>6290.181548</td>\n",
       "      <td>4077.125000</td>\n",
       "      <td>7107.592262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.037141e+00</td>\n",
       "      <td>6.93251</td>\n",
       "      <td>146557.491977</td>\n",
       "      <td>48467.781982</td>\n",
       "      <td>5758.270718</td>\n",
       "      <td>13919.548597</td>\n",
       "      <td>5350.515362</td>\n",
       "      <td>3962.411476</td>\n",
       "      <td>66753.570506</td>\n",
       "      <td>3508.836521</td>\n",
       "      <td>...</td>\n",
       "      <td>4395.753459</td>\n",
       "      <td>8089.586941</td>\n",
       "      <td>16127.871300</td>\n",
       "      <td>9343.563633</td>\n",
       "      <td>4226.126132</td>\n",
       "      <td>11090.738373</td>\n",
       "      <td>1931.305348</td>\n",
       "      <td>9381.722580</td>\n",
       "      <td>6501.804851</td>\n",
       "      <td>10648.331435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>5.75000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.020052e+07</td>\n",
       "      <td>11.50000</td>\n",
       "      <td>12132.000000</td>\n",
       "      <td>3057.000000</td>\n",
       "      <td>-499.500000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>-499.500000</td>\n",
       "      <td>-499.500000</td>\n",
       "      <td>5320.500000</td>\n",
       "      <td>-280.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-338.500000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>787.500000</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>-225.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>-452.500000</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>125.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.020053e+07</td>\n",
       "      <td>17.25000</td>\n",
       "      <td>296543.250000</td>\n",
       "      <td>86349.000000</td>\n",
       "      <td>7297.000000</td>\n",
       "      <td>19499.000000</td>\n",
       "      <td>7167.250000</td>\n",
       "      <td>5059.250000</td>\n",
       "      <td>121476.000000</td>\n",
       "      <td>4996.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>5802.750000</td>\n",
       "      <td>15162.750000</td>\n",
       "      <td>28786.000000</td>\n",
       "      <td>17261.250000</td>\n",
       "      <td>4906.750000</td>\n",
       "      <td>17915.750000</td>\n",
       "      <td>2182.250000</td>\n",
       "      <td>15947.000000</td>\n",
       "      <td>9750.500000</td>\n",
       "      <td>16780.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.020053e+07</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>439173.000000</td>\n",
       "      <td>150733.000000</td>\n",
       "      <td>19038.000000</td>\n",
       "      <td>50026.000000</td>\n",
       "      <td>17634.000000</td>\n",
       "      <td>14861.000000</td>\n",
       "      <td>226740.000000</td>\n",
       "      <td>10638.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15828.000000</td>\n",
       "      <td>21257.000000</td>\n",
       "      <td>48132.000000</td>\n",
       "      <td>26146.000000</td>\n",
       "      <td>15578.000000</td>\n",
       "      <td>35618.000000</td>\n",
       "      <td>5946.000000</td>\n",
       "      <td>29441.000000</td>\n",
       "      <td>19906.000000</td>\n",
       "      <td>31504.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 날짜         시간             10            100           101  \\\n",
       "count  3.360000e+02  336.00000     336.000000     336.000000    336.000000   \n",
       "mean   2.020052e+07   11.50000  118874.625000   36042.446429   3243.547619   \n",
       "std    4.037141e+00    6.93251  146557.491977   48467.781982   5758.270718   \n",
       "min    2.020052e+07    0.00000    -999.000000    -999.000000   -999.000000   \n",
       "25%    2.020052e+07    5.75000    -999.000000    -999.000000   -999.000000   \n",
       "50%    2.020052e+07   11.50000   12132.000000    3057.000000   -499.500000   \n",
       "75%    2.020053e+07   17.25000  296543.250000   86349.000000   7297.000000   \n",
       "max    2.020053e+07   23.00000  439173.000000  150733.000000  19038.000000   \n",
       "\n",
       "                120           121           140            150           160  \\\n",
       "count    336.000000    336.000000    336.000000     336.000000    336.000000   \n",
       "mean    9309.401786   2996.229167   2012.163690   51864.145833   1835.991071   \n",
       "std    13919.548597   5350.515362   3962.411476   66753.570506   3508.836521   \n",
       "min     -999.000000   -999.000000   -999.000000    -999.000000   -999.000000   \n",
       "25%     -999.000000   -999.000000   -999.000000    -999.000000   -999.000000   \n",
       "50%      483.000000   -499.500000   -499.500000    5320.500000   -280.500000   \n",
       "75%    19499.000000   7167.250000   5059.250000  121476.000000   4996.750000   \n",
       "max    50026.000000  17634.000000  14861.000000  226740.000000  10638.000000   \n",
       "\n",
       "       ...          1020          1040          1100          1200  \\\n",
       "count  ...    336.000000    336.000000    336.000000    336.000000   \n",
       "mean   ...   2302.880952   5596.458333  11984.901786   6884.318452   \n",
       "std    ...   4395.753459   8089.586941  16127.871300   9343.563633   \n",
       "min    ...   -999.000000   -999.000000   -999.000000   -999.000000   \n",
       "25%    ...   -999.000000   -999.000000   -999.000000   -999.000000   \n",
       "50%    ...   -338.500000    157.000000    787.500000    466.000000   \n",
       "75%    ...   5802.750000  15162.750000  28786.000000  17261.250000   \n",
       "max    ...  15828.000000  21257.000000  48132.000000  26146.000000   \n",
       "\n",
       "               1510          2510         3000          4510          5510  \\\n",
       "count    336.000000    336.000000   336.000000    336.000000    336.000000   \n",
       "mean    2203.113095   7539.523810   602.684524   6290.181548   4077.125000   \n",
       "std     4226.126132  11090.738373  1931.305348   9381.722580   6501.804851   \n",
       "min     -999.000000   -999.000000  -999.000000   -999.000000   -999.000000   \n",
       "25%     -999.000000   -999.000000  -999.000000   -999.000000   -999.000000   \n",
       "50%     -225.000000    133.000000  -452.500000     68.500000    -90.000000   \n",
       "75%     4906.750000  17915.750000  2182.250000  15947.000000   9750.500000   \n",
       "max    15578.000000  35618.000000  5946.000000  29441.000000  19906.000000   \n",
       "\n",
       "               6000  \n",
       "count    336.000000  \n",
       "mean    7107.592262  \n",
       "std    10648.331435  \n",
       "min     -999.000000  \n",
       "25%     -999.000000  \n",
       "50%      125.500000  \n",
       "75%    16780.500000  \n",
       "max    31504.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "* 한 칼럼에 대한 7일(168행) 데이터를 input_data, 뒤따르는 7일 데이터를 output_data로 반환합니다.\n",
    "* 도로별 차이를 두지 않고 모든 도로를 동일한 타입의 데이터로 취급합니다.\n",
    "* 모든 csv 파일의 마지막 168행은 예측해야하는 값이므로 input으로 들어가지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):      # torch.utils.data.Dataset 클래스의 상속 클래스 CustomDataset class 생성. 상속 클래스 생성시 __init__, __getitem__, __len__함수는 기본적으로 정의해줘야 함.\n",
    "    \n",
    "    def __init__(self, root, seq_len, batch_size=64, phase='train'):      # 데이터 로드 단계에 사용될 여러 변수들을 'self.변수명'의 형태로 지정해두는 함수\n",
    "        \n",
    "        self.root = root      # CustomDataset 객체 생성 시 데이터 경로 앞부분(공통 부분)을 root로 입력받아 저장\n",
    "        self.phase = phase      # CustomDataset 객체 생성 시 데이터 경로 뒷부분(train/validate/test)을 phase로 입력받아 저장\n",
    "        self.label_path = os.path.join(self.root, self.phase + '.csv')      # 데이터 전체 경로 생성\n",
    "        df = pd.read_csv(self.label_path)      # 생성한 데이터 전체 경로로부터 데이터 로드\n",
    "        \n",
    "        self.seq_len = seq_len * 24      # 일 단위 기간을 입력 받은 후 시간 단위 기간으로 변환하여 저장\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = {}\n",
    "        \n",
    "        timestamps = [(i, j) for (i, j) in zip(list(df['날짜']), list(df['시간']))]      # 날짜와 시간 정보가 튜플로 들어 있는 리스트 생성\n",
    "        categories = df.columns.values.tolist()[2:]      # 도로명 column list 생성\n",
    "\n",
    "        input_data = []\n",
    "        output_data = []\n",
    "\n",
    "        for t in range(len(timestamps)):\n",
    "            temp_input_data = []\n",
    "            temp_output_data = []\n",
    "            for col in categories:\n",
    "                road = df[col].tolist()\n",
    "                inp = [float(i) for i in road[t:t+self.seq_len]]      # input 데이터 시계열 구간 설정\n",
    "                outp = [float(j) for j in road[t+self.seq_len:t+2*self.seq_len]]      # output 데이터 시계열 구간 설정\n",
    "                temp_input_data.append(inp) \n",
    "                temp_output_data.append(outp)\n",
    "            input_data.append(temp_input_data)\n",
    "            output_data.append(temp_output_data)\n",
    "            \n",
    "# input_data : [[첫번째 input 기간 동안의 첫번째 도로의 통행량 list, ..., 첫번째 input 기간 동안의 35번째 도로의 통행량 list], ...,\n",
    "#               [마지막 input 기간 동안의 첫번째 도로의 통행량 list, ..., 마지막 input 기간 동안의 35번째 도로의 통행량 list]]\n",
    "# output_data : [[첫번째 output 기간 동안의 첫번째 도로의 통행량 list, ..., 첫번째 output 기간 동안의 35번째 도로의 통행량 list], ...,\n",
    "#                [마지막 output 기간 동안의 첫번째 도로의 통행량 list, ..., 마지막 output 기간 동안의 35번째 도로의 통행량 list]]\n",
    "        \n",
    "        self.labels['timestamp'] = timestamps\n",
    "        self.labels['category'] = categories\n",
    "        self.labels['input'] = input_data\n",
    "        self.labels['output'] = output_data\n",
    "\n",
    "    def __getitem__(self, index):      # index를 가지고 데이터를 하나씩 불러올 수 있게 하는 함수\n",
    "\n",
    "#         데이터 내 index가 부여되는 형태\n",
    "\n",
    "#                 | road_1    road_2    ...  road_35\n",
    "#                -------------------------------------\n",
    "#         time_1  | index_0   index_1   ...  index_34\n",
    "#         time_2  | index_35  index_36  ...  index_69\n",
    "\n",
    "        row = index // 35      # index를 35(도로수)로 나눈 몫  ex) 71//35 -> 2\n",
    "        col = index % 35      # index를 35(도로수)로 나눈 나머지  ex) 71%35 -> 1\n",
    "\n",
    "        timestamp = self.labels['timestamp'][row]      # (날짜, 시간) 튜플이 들어있는 list에서 row번째 시점에 해당하는 튜플\n",
    "        category = self.labels['category'][col]      # 도로명 column list에서 col번째 도로에 해당하는 element\n",
    "        \n",
    "        input_data = torch.tensor(self.labels['input'][row][col])      # input_data list에서, row번째 시점의 col번째 도로 교통량 정보\n",
    "\n",
    "        if self.phase != 'test':\n",
    "            output_data = torch.tensor(self.labels['output'][row][col])\n",
    "        else:\n",
    "            output_data = []\n",
    "\n",
    "        return timestamp, category, (input_data, output_data)\n",
    "\n",
    "    def __len__(self):      # getitem 함수를 통해 데이터를 불러오려면,전체 index 길이를 알아야 한다.\n",
    "        return (len(self.labels['timestamp']) - (self.seq_len * 2) + 1) * 35      # 특정 시점이 아닌 특정 기간을 하나의 data 단위로 설정하면, 전체 샘플 수는 감소함을 반영 \n",
    "\n",
    "\n",
    "def data_loader(root, phase='train', batch_size=64, seq_len=7, drop_last=False):\n",
    "    if phase == 'train':\n",
    "        shuffle = True\n",
    "    else:\n",
    "        shuffle = False\n",
    "\n",
    "    dataset = CustomDataset(root, seq_len, batch_size, phase)\n",
    "    dataloader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size=168,      # input 길이는 168시간(7일 X 24시간)\n",
    "                 hidden_size=1024,\n",
    "                 output_size=168,      # output 길이는 168시간(7일 X 24시간)\n",
    "                 batch_size=64,\n",
    "                 num_layers=3,\n",
    "                 dropout=0,\n",
    "                 batch_first=False):      # batch_first(default=False) : 배치 차원을 첫번째 차원으로 하여 데이터를 불러올 것인지 여부\n",
    "\n",
    "        super(LSTMNet, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        ##### Layer 1\n",
    "        self.lstm1 = nn.LSTM(input_size,\n",
    "                             hidden_size,\n",
    "                             dropout=0.2,\n",
    "                             num_layers=num_layers)\n",
    "\n",
    "        ##### Layer 2\n",
    "        self.lstm2 = nn.LSTM(hidden_size, \n",
    "                             hidden_size,\n",
    "                             dropout=0.2,\n",
    "                             num_layers=num_layers)\n",
    "\n",
    "        ##### Finalize\n",
    "        self.linear = nn.Linear(hidden_size, \n",
    "                                output_size)\n",
    "        \n",
    "        self.activation = nn.LeakyReLU(0.2)\n",
    "\n",
    "        \n",
    "    def forward(self, x, h_in, c_in):\n",
    "\n",
    "        h_in = nn.Parameter(h_in.type(dtype), requires_grad=True)      # gradient descent로 업데이트 되는(requires_grad=True), h_in 이라는 이름의 파라미터 생성 \n",
    "        c_in = nn.Parameter(c_in.type(dtype), requires_grad=True)      # gradient descent로 업데이트 되는(requires_grad=True), c_in 이라는 이름의 파라미터 생성\n",
    "\n",
    "        # Layer 1\n",
    "        lstm_out, (h_1, c_1) = self.lstm1(x, (h_in, c_in))\n",
    "        lstm_out = self.activation(lstm_out)\n",
    "\n",
    "        # Layer2\n",
    "        lstm_out, (h_2, c_2) = self.lstm2(lstm_out, (h_1, c_1))\n",
    "        lstm_out = self.activation(lstm_out)\n",
    "\n",
    "        # Final\n",
    "        predictions = self.linear(lstm_out)\n",
    "        \n",
    "        return predictions, (h_2, c_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 파일과 모델 가중치 파일 저장을 위해 log 디렉토리 생성. 중요한 파일이 덮어씌워지지 않도록 주의\n",
    "os.makedirs('log', exist_ok=True)\n",
    "\n",
    "\n",
    "def save_model(model_name, model, optimizer):\n",
    "    state = {\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(state, os.path.join('log', model_name + '.pth'))\n",
    "    print('model saved\\n')\n",
    "    return os.path.join('log', model_name + '.pth')\n",
    "\n",
    "\n",
    "def load_model(model_name, model, optimizer=None):\n",
    "    state = torch.load(os.path.join(model_name))\n",
    "    model.load_state_dict(state['model'])\n",
    "    if optimizer is not None:\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "model_name = 'sequential'\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "val_epoch = 1\n",
    "base_lr = 0.01\n",
    "seq_len = 7\n",
    "\n",
    "input_size = seq_len * 24\n",
    "output_size = input_size\n",
    "hidden_size = 1024\n",
    "num_layers = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = LSTMNet(input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                output_size=output_size,\n",
    "                batch_size=batch_size,\n",
    "                num_layers=num_layers)\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = Adam(model.parameters(), lr=base_lr)      # optimizer로는 Adam이 가장 무난합니다. Adam을 쓰면 learning_rate를 따로 지정해주지 않아도 알아서 조정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMNet(\n",
      "  (lstm1): LSTM(168, 1024, num_layers=6, dropout=0.2)\n",
      "  (lstm2): LSTM(1024, 1024, num_layers=6, dropout=0.2)\n",
      "  (linear): Linear(in_features=1024, out_features=168, bias=True)\n",
      "  (activation): LeakyReLU(negative_slope=0.2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get data loader\n",
    "train_dataloader = data_loader(root=DATASET_PATH,\n",
    "                               phase='train',\n",
    "                               batch_size=batch_size,\n",
    "                               seq_len=seq_len,\n",
    "                               drop_last=True)\n",
    "\n",
    "validate_dataloader = data_loader(root=DATASET_PATH,\n",
    "                                  phase='validate',\n",
    "                                  batch_size=1,\n",
    "                                  seq_len=seq_len,\n",
    "                                  drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_128630/1655538959.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# 모델을 train mode로 전환. train mode일 때만 적용되어야 하는 drop out 등이 적용될 수 있게 하기 위함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0;31m# enumerate 함수를 통해 train_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         (h_in, c_in) = (torch.zeros(num_layers, batch_size, hidden_size, requires_grad=True).to(device),\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_128630/1931245870.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0moutput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_batch_loss = 0.0\n",
    "train_epoch_loss = 0.0\n",
    "\n",
    "valid_epoch_loss = 0.0\n",
    "valid_min_epoch_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    model.train()      # 모델을 train mode로 전환. train mode일 때만 적용되어야 하는 drop out 등이 적용될 수 있게 하기 위함 \n",
    "\n",
    "    for iter_, sample in enumerate(train_dataloader):      # enumerate 함수를 통해 train_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\n",
    "\n",
    "        (h_in, c_in) = (torch.zeros(num_layers, batch_size, hidden_size, requires_grad=True).to(device),\n",
    "                        torch.zeros(num_layers, batch_size, hidden_size, requires_grad=True).to(device))\n",
    "\n",
    "        _, _, (input_data, output_data) = sample      # train_dataloader에서 불러온 sample은 [[날짜, 시간], [도로], [[input_data],[output_data]]]로 구성됨. 학습에는 [[input_data], [output_data]]만 사용\n",
    "        \n",
    "        input_data = input_data.unsqueeze(0).to(device)\n",
    "        output_data = output_data.unsqueeze(0).to(device)\n",
    "\n",
    "        pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "        \n",
    "        loss = criterion(pred, output_data)\n",
    "\n",
    "        model.zero_grad()    # 파라미터 업데이트는 batch 단위로 이루어지고, 매 batch마다 gradient를 초기화해주어야 함 \n",
    "        loss.backward()      # backpropagation\n",
    "        optimizer.step()      # 파라미터 업데이트\n",
    "        \n",
    "        train_batch_loss += loss.item()\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "        if iter_ % 400 == 399:      # 400개의 batch마다 training Loss 출력\n",
    "            print('Train Epoch: {:2} | Batch: {:4} | Loss: {:1.2f}'.format(epoch, iter_+1, train_batch_loss/400))\n",
    "            train_batch_loss = 0\n",
    "            \n",
    "    train_epoch_loss = 0.0\n",
    "\n",
    "    \n",
    "    model.eval()      # 모델을 eval mode로 전환. eval mode에서 적용되면 안되는 drop out 등이 적용되지 않게 하기 위함\n",
    "\n",
    "    with torch.no_grad():      # validation / test set에 대해서는 weight 및 bias의 update, 즉, gradient descent가 일어나지 않도록 no_grad()를 선언\n",
    "        (h_in, c_in) = (torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device),\n",
    "                        torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device))\n",
    "\n",
    "        for iter_, sample in enumerate(validate_dataloader):      # enumerate 함수를 통해 validate_dataloader에서 'batch의 index'와 'batch'를 순서대로 호출\n",
    "\n",
    "            _, _, (input_data, output_data) = sample      # validate_dataloader에서 불러온 sample은 [[날짜, 시간], [도로], [[input_data],[output_data]]]로 구성됨. validation에는 [[input_data], [output_data]]만 사용\n",
    "\n",
    "            input_data = input_data.unsqueeze(0).to(device)\n",
    "            output_data = output_data.unsqueeze(0).to(device)\n",
    "\n",
    "            pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "            loss = criterion(pred, output_data)\n",
    "            valid_epoch_loss += loss.item()\n",
    "\n",
    "        print('\\nValid Epoch: {:2} | Loss: {:1.2f}'.format(epoch, valid_epoch_loss/len(validate_dataloader)))\n",
    "\n",
    "        if valid_epoch_loss < valid_min_epoch_loss:\n",
    "            save_model('best', model, optimizer)\n",
    "            valid_min_epoch_loss = valid_epoch_loss\n",
    "\n",
    "        valid_epoch_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "seq_len = 7\n",
    "\n",
    "input_size = seq_len * 24\n",
    "hidden_size = 1024\n",
    "output_size = input_size\n",
    "batch_size = 1\n",
    "num_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = data_loader(root=DATASET_PATH,\n",
    "                              phase='test',\n",
    "                              batch_size=batch_size,\n",
    "                              seq_len=seq_len,\n",
    "                              drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model = LSTMNet(input_size=input_size,\n",
    "                hidden_size=hidden_size,\n",
    "                output_size=output_size,\n",
    "                batch_size=batch_size,\n",
    "                num_layers=num_layers)\n",
    "\n",
    "# model\n",
    "model_name = 'log/best.pth'\n",
    "\n",
    "load_model(model_name, model)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file_path = os.path.join(DATASET_PATH, 'sample_submission.csv')\n",
    "submission_table = pd.read_csv(submission_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_in, c_in) = (torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device),\n",
    "                torch.zeros(num_layers, 1, hidden_size, requires_grad=False).to(device))\n",
    "\n",
    "for iter_, sample in enumerate(test_dataloader):\n",
    "\n",
    "    timestamp, category, (input_data, output_data) = sample\n",
    "    input_data = input_data.unsqueeze(0).to(device)\n",
    "\n",
    "    pred, (h_in, c_in) = model(input_data, h_in, c_in)\n",
    "\n",
    "    for i, (t, h) in enumerate(zip(timestamp[0], timestamp[1])):\n",
    "        for cat, row in zip(category, pred[0]):\n",
    "            cat = f'{cat}'\n",
    "            submission_table[cat] = row.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_table.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
